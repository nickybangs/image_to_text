{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.display import Image \n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import config\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from PIL import Image as pil_im\n",
    "from PIL import ImageEnhance\n",
    "from imageio import imwrite\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from fastai.core import Path\n",
    "\n",
    "from fastai.vision import Image as fast_im\n",
    "from time import time\n",
    "import yaml\n",
    "\n",
    "import dill\n",
    "import cloudpickle \n",
    "dill._dill._reverse_typemap['ClassType'] = type\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_graph import *\n",
    "from line_bounds import *\n",
    "from pred_handler import get_top_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load models and create image graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;color:#FFB5A4\">After all of the lines are split and stored in image files, we can split each one into it's individual characters <span style=\"font-size:13px;\">(or sometimes character parts, or multiple characters -- see dataset generation notebook)</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.loss.CrossEntropyLoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveMaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm1d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/anaconda3/lib/python3.6/site-packages/torch/serialization.py:453: SourceChangeWarning: source code of class 'torch.nn.modules.loss.MSELoss' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "line_source = Path('../greek_pages/line_images/LAT_RDR_PG2')\n",
    "\n",
    "lang_model = dill.load(open('../models/latin_lang_model.pkl','rb'))\n",
    "config.model = load_learner('../models/', 'latin_model.pkl') # model to classify a character component\n",
    "splitter_model = load_learner('../models/', 'split_model.pkl') # model to split components containing multiple characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">For this notebook we will just parse one line, in general each line will be parsed with the following methodology and compiled together into a final text document</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../greek_pages/line_images/LAT_RDR_PG2/line_13.jpeg')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_path = line_source.ls()[0]; line_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_path = Path('../greek_pages/line_images/LAT_RDR_PG2/line_2.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a346b8d30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = Path('../greek_pages/line_graphs/')\n",
    "graph_name = line_path.name.replace('.jpg','.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_image_array(line_path)\n",
    "config.rows, config.cols = img.shape # set config parameters used by the graph processing algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;color:#FFB5A4\">Get a graph representation of the line as well as all the connected components - these represent the individual characters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[27377 -> 29934, 0.0, 27377 -> 29935, 0.0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.adj[27377]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(121, 2557)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{27376: (1806, 1809, 10, 11),\n",
       " 35046: (1796, 1824, 12, 47),\n",
       " 96333: (1666, 1777, 28, 68),\n",
       " 80854: (1579, 1600, 31, 71),\n",
       " 91536: (2040, 2044, 35, 38),\n",
       " 95534: (902, 935, 36, 78),\n",
       " 129076: (1220, 1343, 36, 79),\n",
       " 93537: (1485, 1494, 36, 44),\n",
       " 95395: (779, 799, 37, 76),\n",
       " 95891: (1282, 1285, 37, 39),\n",
       " 100490: (766, 775, 39, 45),\n",
       " 100853: (1122, 1175, 39, 79),\n",
       " 101372: (1601, 1667, 39, 70),\n",
       " 105726: (889, 897, 40, 48),\n",
       " 103560: (1278, 1286, 40, 48),\n",
       " 103611: (1330, 1339, 40, 48),\n",
       " 106395: (1557, 1560, 41, 44),\n",
       " 106463: (1626, 1628, 41, 43),\n",
       " 110544: (586, 617, 42, 72),\n",
       " 108938: (1533, 1560, 42, 72),\n",
       " 110580: (617, 644, 43, 73),\n",
       " 113163: (646, 673, 44, 74),\n",
       " 121607: (1427, 1533, 44, 75),\n",
       " 115740: (674, 734, 45, 75),\n",
       " 120915: (735, 760, 46, 75),\n",
       " 119030: (1396, 1426, 46, 76),\n",
       " 123498: (761, 779, 47, 76),\n",
       " 121556: (1359, 1395, 47, 76),\n",
       " 123560: (817, 850, 48, 89),\n",
       " 126144: (851, 904, 48, 78),\n",
       " 128818: (938, 1019, 48, 79),\n",
       " 123733: (997, 1000, 48, 50),\n",
       " 131462: (1054, 1089, 49, 79),\n",
       " 126395: (1090, 1120, 49, 79),\n",
       " 126476: (1176, 1202, 49, 79),\n",
       " 137295: (1774, 1776, 53, 55),\n",
       " 144657: (1464, 1467, 56, 58),\n",
       " 144974: (1781, 1791, 56, 70),\n",
       " 148191: (2440, 2452, 57, 64),\n",
       " 182573: (1024, 1033, 71, 84),\n",
       " 249338: (1309, 1313, 97, 99),\n",
       " 254381: (1238, 1242, 99, 101),\n",
       " 261951: (1137, 1140, 102, 104),\n",
       " 264344: (973, 976, 103, 104),\n",
       " 269458: (973, 975, 105, 107),\n",
       " 271702: (660, 662, 106, 108)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "G = get_graph(graph_path, graph_name, line_path)\n",
    "c = get_components(G)\n",
    "with open('../yaml/letter_map_inverse_english.yaml') as f: # get inverse letter-maps to convert from letter code to character\n",
    "    lm_inv = yaml.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from split_multi import * \n",
    "from image_handling import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get preds for each component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">For each component, predict the letter with the classifier (see training details for info on model)\n",
    "    <br/><br/>\n",
    "   Add the top 3 predictions as candidates, the final letter decision will be made by a character level language model</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "s = []\n",
    "for l in c:\n",
    "    lb, ub, lbr, ubr = c[l]\n",
    "    im = get_fast_im(img[lbr:ubr, lb:ub])\n",
    "    ltrs = [get_top_preds(im, imtype='image', top=3)]\n",
    "    s.append((lb,ub,ltrs,l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">Quick look at the predictions for the first few characters</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = get_words(sorted(s, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../greek_pages/line_images/LAT_RDR_PG2/line_13.jpeg\" style=\"width: 700px; height=150px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vertical_neighbor(letter, neighbors):\n",
    "    left, right = neighbors\n",
    "    lb, ub, lbr, ubr = zip(c[letter], c[left])\n",
    "    lb, ub, lbr, ubr = min(lb), max(ub), min(lbr), max(ubr)\n",
    "    return lb, ub, lbr, ubr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb, ub, lbr, ubr =get_vertical_neighbor(102849,(82434,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[lbr:ubr, lb:ub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts, rights = get_sp_ims(img[lbr:ubr, lb:ub].T,.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lefts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_preds(lefts[0],imtype='image',top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_preds(rights[0],imtype='image',top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newll, newlr = get_sp_ims(np.asarray(lefts[0].data[2]*265).T,.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newrl, newrr = get_sp_ims(np.asarray(rights[0].data[2]*265).T,.5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newrl[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newrr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_preds(newrl[0],imtype='image',top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_preds(newrr[0],imtype='image',top=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word options = 'hil', 'nil', 'h1l', 'n1l', etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.S('h',('**','**')), lang_model.S('h',('**','**'))*.077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.S('n',('**','**')), lang_model.S('n',('**','**'))*.0758"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.S('i',('**','h')), lang_model.S('i',('**','h'))*.002, lang_model.S('i',('**','h'))*.002*.411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.S('i',('**','n')), lang_model.S('i',('**','n'))*.004, lang_model.S('i',('**','h'))*.004*.411"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = lang_model.S('l', ('h','i')) * .00012 * .41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.S('l', ('h','i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.S('l', ('n','i'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = lang_model.S('l', ('n','i')) * .00024 * .41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(p1,p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_model.S('i',('**','t'))*.15\n",
    "\n",
    "lang_model.S('t',('**','t'))*0.7619\n",
    "\n",
    "lang_model.S('n',('**','**'))*.4\n",
    "\n",
    "lb, ub, lbr, ubr = c[com]\n",
    "\n",
    "get_top_preds(get_fast_im(img[lbr:ubr, lb:ub]),imtype='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newl[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">Now we will create a first attempt at a text version of the line</p> \n",
    "\n",
    "<p style=\"font-size:15px;color:#FFB5A4\">For each character, if it is a multi we will split it (see below) and then add each sub-image. If not we just add the letter, using its prediction, its left boundary (pxl number) and the right boundary of the character before. See function def below</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb, ub, lbr, ubr = c[ltr[-1]]\n",
    "imwrite('temp.jpg', img[lbr:ubr, lb:ub])\n",
    "sp_splits, mdl_split = get_mult(Path('temp.jpg'))\n",
    "l1, l2 = get_best_letters(sp_splits, mdl_split)\n",
    "[(l1, l2 )]+ [p for p in ltr[2][0] if p[0] != 'multi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for w in words:\n",
    "    w = filter_letters(w)\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prob = 0\n",
    "max_string = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "for word in product(ltr_1, ltr_2, ltr_3, ltr_4, ltr_5, ltr_6):\n",
    "    nword = []\n",
    "    for w in word:\n",
    "        if isinstance(w[0], tuple):\n",
    "            nword.append(w[0])\n",
    "            nword.append(w[1])\n",
    "        else:\n",
    "            nword.append(w)\n",
    "    word_str = [('**',1),('**',1)] + nword + [('**STOP**',1)]\n",
    "    i = 2\n",
    "    prob = 1\n",
    "    while i < len(word_str):\n",
    "        try:\n",
    "            prob *= lang_model.S(word_str[i][0], (word_str[i-2][0], word_str[i-1][0]))*word_str[i][1]\n",
    "        except:\n",
    "            prob = 0\n",
    "        i += 1\n",
    "    if prob > max_prob:\n",
    "        max_prob = prob\n",
    "        max_string = ''.join([w[0] for w in nword])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = list(product(l1,l2)) + [p for p in ltr[2][0] if p[0] != 'multi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function definitions below\n",
    "for i,ltr in enumerate(srted):\n",
    "    if 'multi' in ltr[2]:\n",
    "        lb, ub, lbr, ubr = c[ltr[-1]]\n",
    "        imwrite('temp.jpg', img[lbr:ubr, lb:ub])\n",
    "        sp_splits, mdl_split = get_mult(Path('temp.jpg'))\n",
    "        l1, l2 = get_best_letters(sp_splits, mdl_split)\n",
    "        line += add_letter(l1, srted[max(i-1,0)][1], ltr[0])\n",
    "        line += add_letter(l2, ltr[0], ltr[0])\n",
    "    else:\n",
    "        if ltr[2] != ['noise']:\n",
    "            line += add_letter(ltr[2], srted[max(i-1,0)][1], ltr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">Here is the image of the line, as well as the text generated by the current model and parser. Currently I allow both options for predictions with prob. below .8 separating them by a / character. In a final conversion I would return the argmax. However the future version will use a language model to chose between the top 2 or 3 preds, multiplying the letter probability by the probability of the word generated with that letter. This will most likely not be an issue often in practice since often only one of the options will be an actual word.</p> <br/>\n",
    "<p style=\"font-size:15px;color:#FFB5A4\">As of now the model has primarily been trained on greek data with only a few english samples, so as I expand that data set the performance on english letters will improve dramatically.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../greek_pages/line_images/line_1.jpg\" style=\"width: 700px; height=150px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">This next function attempts to split an image classified as 'multi' into two sub-characters using two methods:</p>\n",
    "<ul style=\"font-size:15px;color:#FFB5A4\">\n",
    "    <li>a shortest path from the estimated split point to the bottom of the image</li>\n",
    "    <li>a straight line from that point</li></ul>\n",
    "<br/>\n",
    "<p style=\"font-size:15px;color:#FFB5A4\">the argmax probabilities of each the letters are multiplied together to get a score, the higher score is chosen as the correct split</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
