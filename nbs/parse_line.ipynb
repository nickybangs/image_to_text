{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.display import Image \n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "from PIL import Image as pil_im\n",
    "from PIL import ImageEnhance\n",
    "from imageio import imwrite\n",
    "from fastai.core import Path\n",
    "from fastai.vision import load_learner, open_image\n",
    "from fastai.vision import Image as fast_im\n",
    "from time import time\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_graph import *\n",
    "from line_bounds import *\n",
    "from pred_handler import get_top_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;color:#FFB5A4\">After all of the lines are split and stored in image files, we can split each one into it's individual characters <span style=\"font-size:13px;\">(or sometimes character parts, or multiple characters -- see dataset generation notebook)</span></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_source = Path('../greek_pages/line_images/')\n",
    "\n",
    "config.model = load_learner('../models/', 'rn_34.pkl') # model to classify a character component\n",
    "splitter_model = load_learner('../models/', 'split_model.pkl') # model to split components containing multiple characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">For this notebook we will just parse one line, in general each line will be parsed with the following methodology and compiled together into a final text document</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('../greek_pages/line_images/line_1.jpg')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line_path = line_source.ls()[1]; line_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = Path('../greek_pages/line_graphs/')\n",
    "graph_name = line_path.name.replace('.jpg','.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = get_image_array(line_path)\n",
    "config.rows, config.cols = img.shape # set config parameters used by the graph processing algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:16px;color:#FFB5A4\">Get a graph representation of the line as well as all the connected components - these represent the individual characters</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = get_graph(graph_path, graph_name, line_path)\n",
    "c = get_components(G)\n",
    "with open('letter_map_inverse.yaml') as f: # get inverse letter-maps to convert from letter code to character\n",
    "    lm_inv = yaml.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">For each component, predict the letter with the classifier (see training details for info on model)\n",
    "    <br/><br/>\n",
    "    If the top prediction is > .8 probability, append only that letter to the list of characters, else add the top two predictions.</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for l in c:\n",
    "    lb, ub, lbr, ubr = c[l]\n",
    "    imwrite('temp.jpg', img[lbr:ubr, lb:ub])\n",
    "    top_preds = get_top_preds('temp.jpg',2)\n",
    "    if top_preds[0][1] > .8:\n",
    "        ltrs = [top_preds[0][0]]\n",
    "    else:\n",
    "        ltrs = [top_preds[0][0], top_preds[1][0]]\n",
    "    s.append((lb,ub,ltrs,l))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">Quick look at the predictions for the first few characters</p> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(147, 176, ['breathlessaccute'], 13611),\n",
       " (145, 180, ['α'], 75532),\n",
       " (180, 212, ['χ'], 78253),\n",
       " (212, 238, ['θ'], 40601),\n",
       " (239, 303, ['multi'], 75627)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(s, key=lambda x: x[1])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">Now we will create a first attempt at a text version of the line</p> \n",
    "\n",
    "<p style=\"font-size:15px;color:#FFB5A4\">For each character, if it is a multi we will split it (see below) and then add each sub-image. If not we just add the letter, using its prediction, its left boundary (pxl number) and the right boundary of the character before. See function def below</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run function definitions below\n",
    "line = ''\n",
    "srted = sorted(s, key=lambda x: x[1])\n",
    "for i,ltr in enumerate(srted):\n",
    "    if 'multi' in ltr[2]:\n",
    "        lb, ub, lbr, ubr = c[ltr[-1]]\n",
    "        imwrite('temp.jpg', img[lbr:ubr, lb:ub])\n",
    "        sp_splits, mdl_split = get_mult(Path('temp.jpg'))\n",
    "        l1, l2 = get_best_letters(sp_splits, mdl_split)\n",
    "        line += add_letter(l1, srted[max(i-1,0)][1], ltr[0])\n",
    "        line += add_letter(l2, ltr[0], ltr[0])\n",
    "    else:\n",
    "        if ltr[2] != ['noise']:\n",
    "            line += add_letter(ltr[2], srted[max(i-1,0)][1], ltr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">Here is the image of the line, as well as the text generated by the current model and parser. Currently I allow both options for predictions with prob. below .8 separating them by a / character. In a final conversion I would return the argmax. However the future version will use a language model to chose between the top 2 or 3 preds, multiplying the letter probability by the probability of the word generated with that letter. This will most likely not be an issue often in practice since often only one of the options will be an actual word.</p> <br/>\n",
    "<p style=\"font-size:15px;color:#FFB5A4\">As of now the model has primarily been trained on greek data with only a few english samples, so as I expand that data set the performance on english letters will improve dramatically.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../greek_pages/line_images/line_1.jpg\" style=\"width: 700px; height=150px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'῎αχθο/υματ/t ᾽αχθ´εσομαι, ῀/.-, -./,, ῎ηχθηματ ᾽ηχθ´εσθην b/hecοme νeχed w/῍./-lτ/th (+ d/fαt/τ.) .'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;color:#FFB5A4\">This next function attempts to split an image classified as 'multi' into two sub-characters using two methods:</p>\n",
    "<ul style=\"font-size:15px;color:#FFB5A4\">\n",
    "    <li>a shortest path from the estimated split point to the bottom of the image</li>\n",
    "    <li>a straight line from that point</li></ul>\n",
    "<br/>\n",
    "<p style=\"font-size:15px;color:#FFB5A4\">the argmax probabilities of each the letters are multiplied together to get a score, the higher score is chosen as the correct split</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mult(imname):\n",
    "    im = pil_im.open(imname)\n",
    "    enhancer = ImageEnhance.Contrast(im)\n",
    "    enhanced_im = enhancer.enhance(4.0)\n",
    "    newim_name = \"{}_enhanced.jpg\".format(imname.name)\n",
    "    enhanced_im.save(newim_name)\n",
    "    ip = splitter_model.predict(open_image(newim_name))[1][0][1] # get estimated split point\n",
    "    frac = .5 + round(float(ip),2)\n",
    "    i1, i2 = split_parts(open_image(newim_name), frac, ('md_l1.jpg','md_l2.jpg')) # gets straight line split\n",
    "    \n",
    "    im_arr = get_image_array(newim_name)\n",
    "    G = get_line_graph(im_arr.T) \n",
    "    source = round(im_arr.T.shape[0] * frac)*im_arr.T.shape[1] + 1 \n",
    "    sp = DijsktraSP(G, source) \n",
    "    sp_inds, totalweight = get_sp(G, s=source) \n",
    "    sp_inds.stack.append(source) \n",
    "    left,right = get_split_images(im_arr.T, sp_inds, 0, im_arr.T) # gets shortest path splits\n",
    "    imwrite('sp_l1.jpg', left)\n",
    "    imwrite('sp_l2.jpg', right)\n",
    "    \n",
    "    return ('sp_l1.jpg', 'sp_l2.jpg'), (i1, i2)\n",
    "\n",
    "\n",
    "# gets the sub-letters generated by the two split methods with the higher score\n",
    "def get_best_letters(sp_splits, mdl_splits):\n",
    "    sp1 = get_top_preds(sp_splits[0], top=2)\n",
    "    sp2 = get_top_preds(sp_splits[1], top=2)\n",
    "    md1 = get_top_preds(mdl_splits[0], top=2)\n",
    "    md2 = get_top_preds(mdl_splits[1], top=2)\n",
    "    sp_score = sp1[0][1] * sp2[0][1]\n",
    "    md_score = md1[0][1] * md2[0][1]\n",
    "    if sp_score > md_score:\n",
    "        sp1 = get_letter(sp1)\n",
    "        sp2 = get_letter(sp2)\n",
    "        return sp1, sp2\n",
    "    else:\n",
    "        md1 = get_letter(md1)\n",
    "        md2 = get_letter(md2)\n",
    "        return md1, md2\n",
    "    \n",
    "\n",
    "# if the top probability is greater than 80% return just the top letter, else return the top two\n",
    "def get_letter(ltr): \n",
    "    if ltr[0][1] > .8:\n",
    "        return [ltr[0][0]]\n",
    "    else:\n",
    "        return [ltr[0][0], ltr[1][0]]\n",
    "    \n",
    "\n",
    "# use the predicted split-point to return the two sub-characters\n",
    "def split_parts(img, split_frac, names=None):\n",
    "    left_im = img.data[:,:,:int(img.data.shape[2]*split_frac)+1]\n",
    "    right_im = img.data[:,:,int(img.shape[2]*split_frac):]\n",
    "    if names == None:\n",
    "        return fast_im(left_im), fast_im(right_im)\n",
    "    else:\n",
    "        fast_im(left_im).save(names[0])\n",
    "        fast_im(right_im).save(names[1])\n",
    "        return names\n",
    "\n",
    "\n",
    "# if the two characters are within 10 pxls of eachother, place them next to each other, else add a space\n",
    "def add_letter(ltrs, lbound, rbound):\n",
    "    l = ''\n",
    "    if rbound - lbound > 10:\n",
    "        l += ' '\n",
    "    return l + '/'.join([lm_inv[l] for l in ltrs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
